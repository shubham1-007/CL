{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains information about housing prices in a specific real estate \n",
    "market. It includes various attributes such as property characteristics, location, sale prices, \n",
    "and other relevant features. The goal is to perform data wrangling to gain insights into the \n",
    "factors influencing housing prices and prepare the dataset for further analysis or modeling.\n",
    "Tasks to Perform:\n",
    "1. Import the \"RealEstate_Prices.csv\" dataset. Clean column names by removing spaces, \n",
    "special characters, or renaming them for clarity.\n",
    "2. Handle missing values in the dataset, deciding on an appropriate strategy (e.g., \n",
    "imputation or removal).\n",
    "3. Perform data merging if additional datasets with relevant information are available \n",
    "(e.g., neighborhood demographics or nearby amenities).\n",
    "4. Filter and subset the data based on specific criteria, such as a particular time period, \n",
    "property type, or location.\n",
    "5. Handle categorical variables by encoding them appropriately (e.g., one-hot encoding or \n",
    "label encoding) for further analysis.\n",
    "6. Aggregate the data to calculate summary statistics or derived metrics such as average \n",
    "sale prices by neighborhood or property type.\n",
    "7. Identify and handle outliers or extreme values in the data that may affect the analysis \n",
    "or modelingÂ process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b1f17ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    No  transactiondate  houseage   distance  latitude  longitude  unit_area   \n",
      "7    8         2013.417      20.3  287.60250  24.98042  121.54228       46.7  \\\n",
      "10  11         2013.083      34.8  405.21340  24.97349  121.53372       41.4   \n",
      "11  12         2013.333       6.3   90.45606  24.97433  121.54310       58.1   \n",
      "18  19         2013.417      16.9  368.13630  24.96750  121.54451       42.3   \n",
      "21  22         2013.417      10.5  279.17260  24.97528  121.54541       51.6   \n",
      "\n",
      "    stores_0  stores_1  stores_3  stores_4  stores_5  stores_6  stores_7   \n",
      "7      False     False     False     False     False      True     False  \\\n",
      "10     False      True     False     False     False     False     False   \n",
      "11     False     False     False     False     False     False     False   \n",
      "18     False     False     False     False     False     False     False   \n",
      "21     False     False     False     False     False     False      True   \n",
      "\n",
      "    stores_8  stores_9  stores_10  \n",
      "7      False     False      False  \n",
      "10     False     False      False  \n",
      "11     False      True      False  \n",
      "18      True     False      False  \n",
      "21     False     False      False  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Import the dataset and clean column names\n",
    "data = pd.read_csv(\"realestate.csv\")\n",
    "data.columns = data.columns.str.strip()  # Remove leading/trailing spaces\n",
    "\n",
    "# 2. Handle missing values (You need to decide on the strategy)\n",
    "# Example: Let's assume we want to remove rows with missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# 3. Perform data merging if additional datasets are available (not provided here)\n",
    "\n",
    "# 4. Filter and subset the data based on specific criteria\n",
    "# Example: Filter based on a particular year and distance\n",
    "filtered_data = data[(data['transactiondate'] >= 2013) & (data['distance'] <= 500)]\n",
    "\n",
    "# 5. Handle categorical variables by one-hot encoding (if applicable)\n",
    "# Example: If 'stores' is a categorical variable\n",
    "filtered_data = pd.get_dummies(filtered_data, columns=['stores'])\n",
    "\n",
    "# 6. Aggregate the data to calculate summary statistics\n",
    "# Example: Calculate average sale price by property age\n",
    "average_price_by_age = filtered_data.groupby('houseage')['unit_area'].mean()\n",
    "\n",
    "# 7. Identify and handle outliers\n",
    "# Example: Remove rows with extreme values in 'unit_area'\n",
    "lower_bound = filtered_data['unit_area'].quantile(0.05)\n",
    "upper_bound = filtered_data['unit_area'].quantile(0.95)\n",
    "filtered_data = filtered_data[(filtered_data['unit_area'] >= lower_bound) & (filtered_data['unit_area'] <= upper_bound)]\n",
    "\n",
    "# Display the processed DataFrame\n",
    "print(filtered_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047302c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
